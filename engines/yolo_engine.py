import cv2
import time
import os
import numpy as np
from ultralytics import YOLO
from tkinter import messagebox
from utils.report_utils import save_test_report

timestamp = time.strftime("%Y%m%d_%H%M%S")
class YoloTester:
    def __init__(self, model_path, video_path, output_folder, imgsz, stride, conf, iou, stop_event, tracker_type="bytetrack.yaml"):
        self.model_path = model_path
        self.video_path = video_path
        self.output_folder = output_folder
        self.imgsz = imgsz
        self.stride = stride
        self.conf = conf
        self.iou = iou
        self.stop_event = stop_event
        self.tracker_type = tracker_type

    def run(self):
        # --- C·∫§U H√åNH GIAO DI·ªÜN ---
        DRAW_CFG = {
            "box_thick": 2,          # ƒê·ªô d√†y khung h√¨nh ch·ªØ nh·∫≠t
            "font_scale": 0.6,       # C·ª° ch·ªØ
            "font_thick": 1,         # ƒê·ªô ƒë·∫≠m c·ªßa ch·ªØ
            "text_bg_alpha": 0.5,    # ƒê·ªô trong su·ªët n·ªÅn ch·ªØ (0-1)
            "show_conf": True,       # Hi·ªán ƒë·ªô tin c·∫≠y
            
            # Mapping ID class sang t√™n hi·ªÉn th·ªã v√† m√†u s·∫Øc (BGR)
            "classes": {
                0: {"name": "F-Boat", "color": (0, 0, 255)},    # ƒê·ªè (Fishing)
                1: {"name": "P-Ship", "color": (255, 255, 0)},  # Xanh ng·ªçc (Passenger)
                2: {"name": "S-Boat", "color": (0, 255, 0)},    # Xanh l√° (Speed)
                # Th√™m m·∫∑c ƒë·ªãnh n·∫øu c√≥ class l·∫°
                "default": {"name": "Obj", "color": (255, 255, 255)} 
            }
        }

        try:
            print(f"üîπ Loading model: {self.model_path}")
            model = YOLO(self.model_path)
        except Exception as e:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ load model:\n{e}")
            return

        cap = cv2.VideoCapture(self.video_path)
        if not cap.isOpened():
            messagebox.showerror("L·ªói", f"Kh√¥ng m·ªü ƒë∆∞·ª£c video:\n{self.video_path}")
            return

        # Setup Video Writer
        orig_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        orig_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        orig_fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        input_name = os.path.splitext(os.path.basename(self.video_path))[0]
        model_name = os.path.splitext(os.path.basename(self.model_path))[0]
        tracker_tag = self.tracker_type.replace('.yaml', '').upper()
        tag = f"sz{self.imgsz}_skip{self.stride}_{tracker_tag}_CUSTOM"
        
        out_vid_name = f"{model_name}_vs_{input_name}_{tag}.mp4"
        out_vid_path = os.path.join(self.output_folder, out_vid_name)
        out = cv2.VideoWriter(out_vid_path, cv2.VideoWriter_fourcc(*'mp4v'), orig_fps, (orig_w, orig_h))

        # Setup Window
        window_name = f"YOLO Custom Draw - {model_name}"
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 1280, 720)

        frame_idx = 0 # KH·ªûI T·∫†O T·ª™ 0 ƒê·ªÇ KH·ªöP V·ªöI DARKLABEL
        processed_count = 0
        frame_data = []
        all_confs = []
        unique_ids = set()

        # M·∫£ng l∆∞u k·∫øt qu·∫£ MOT
        mot_predictions = []

        while cap.isOpened() and not self.stop_event.is_set():
            success, frame = cap.read()
            if not success: break
            
            # --- S·ª¨A L·ªñI ƒê·∫æM FRAME ƒê·ªÇ KH√îNG B·ªä L·ªÜCH PHA V·ªöI GT ---
            if (frame_idx + 1) % self.stride != 0: 
                frame_idx += 1
                continue 

            processed_count += 1
            start_t = time.time()
            
            # Tracking
            results = model.track(frame, persist=True, verbose=False, conf=self.conf, iou=self.iou, imgsz=self.imgsz, tracker=self.tracker_type)
            
            end_t = time.time()
            fps_curr = 1.0 / (end_t - start_t) if (end_t - start_t) > 0 else 0
            
            # --- LOGIC V·∫º LABEL ---
            annotated_frame = frame.copy() # Copy ·∫£nh g·ªëc ƒë·ªÉ v·∫Ω
            overlay = frame.copy()         # Layer ƒë·ªÉ v·∫Ω ƒë·ªô trong su·ªët (transparency)
            
            boxes = results[0].boxes
            
            if len(boxes) > 0:
                # L·∫•y d·ªØ li·ªáu d·∫°ng array ƒë·ªÉ x·ª≠ l√Ω nhanh h∆°n
                xyxys = boxes.xyxy.cpu().numpy().astype(int)
                ids = boxes.id.cpu().numpy().astype(int) if boxes.id is not None else [-1]*len(boxes)
                clss = boxes.cls.cpu().numpy().astype(int)
                confs = boxes.conf.cpu().numpy()
                
                # L∆∞u ID ƒë·ªÉ th·ªëng k√™
                for t_id in ids:
                    if t_id != -1: unique_ids.add(t_id)
                    
                # V√≤ng l·∫∑p v·∫Ω t·ª´ng box
                for box, track_id, cls_id, conf in zip(xyxys, ids, clss, confs):
                    x1, y1, x2, y2 = box

                    # L∆∞u m·∫£ng MOT
                    w = x2 - x1
                    h = y2 - y1

                    # Th√¥ng tin tracking (10 c·ªôt)
                    if track_id != -1:
                        mot_line = f"{frame_idx},{track_id},{x1},{y1},{w},{h},{conf:.4f},{cls_id},-1,-1"
                        mot_predictions.append(mot_line)
                        
                    # 1. L·∫•y th√¥ng tin class t·ª´ Config
                    class_info = DRAW_CFG["classes"].get(cls_id, DRAW_CFG["classes"]["default"])
                    color = class_info["color"]
                    label_name = class_info["name"]
                    
                    # 2. V·∫Ω Box (Khung h√¨nh ch·ªØ nh·∫≠t)
                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, DRAW_CFG["box_thick"])
                    
                    # 3. T·∫°o Label text
                    id_text = f"#{track_id}" if track_id != -1 else ""
                    conf_text = f"{conf:.2f}" if DRAW_CFG["show_conf"] else ""
                    label = f"{id_text} {label_name} {conf_text}".strip()
                    
                    # 4. T√≠nh to√°n k√≠ch th∆∞·ªõc n·ªÅn ch·ªØ
                    (w_text, h_text), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, DRAW_CFG["font_scale"], DRAW_CFG["font_thick"])
                    
                    # ƒê·∫∑t v·ªã tr√≠ ch·ªØ
                    text_y = y1 - 5 if y1 - h_text - 5 > 0 else y1 + h_text + 5
                    
                    # 5. V·∫Ω n·ªÅn ch·ªØ TRONG SU·ªêT
                    cv2.rectangle(overlay, 
                                  (x1, text_y - h_text - 5), 
                                  (x1 + w_text, text_y + baseline), 
                                  color, -1) 
                    
                    # V·∫Ω l√™n frame ch√≠nh
                    cv2.putText(annotated_frame, label, (x1, text_y), 
                                cv2.FONT_HERSHEY_SIMPLEX, DRAW_CFG["font_scale"], (255, 255, 255), DRAW_CFG["font_thick"], cv2.LINE_AA)

            # --- G·ªòP LAYER TRONG SU·ªêT ---
            alpha = 1 - DRAW_CFG["text_bg_alpha"]
            annotated_frame = cv2.addWeighted(overlay, 1 - alpha, annotated_frame, alpha, 0)

            # --- V·∫º TH·ªêNG K√ä (UI) ---
            cv2.rectangle(annotated_frame, (5, 5), (250, 85), (0, 0, 0), -1) 
            cv2.putText(annotated_frame, f"FPS: {fps_curr:.1f}", (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)
            cv2.putText(annotated_frame, f"Objs Current: {len(boxes)}", (15, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 1)
            cv2.putText(annotated_frame, f"Total Count: {len(unique_ids)}", (15, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 1)
            
            out.write(annotated_frame)
            cv2.imshow(window_name, annotated_frame)

            # Collect Data
            if len(boxes) > 0: all_confs.extend(confs)
            if processed_count > 1:
                frame_data.append({
                    "Frame": frame_idx, "FPS": round(fps_curr, 2),
                    "Time_ms": round((end_t - start_t)*1000, 2),
                    "Objects_In_Frame": len(boxes),
                    "Total_Unique_Objects": len(unique_ids)
                })

            # TƒÇNG FRAME_IDX ·ªû CU·ªêI V√íNG L·∫∂P
            frame_idx += 1

            if cv2.waitKey(1) & 0xFF == ord('q'): break

        # L∆∞u file pred.txt
        pred_file = f"pred_{input_name}_{timestamp}.txt"
        pred_path = os.path.join(self.output_folder, pred_file)
        
        with open(pred_path, 'w') as f:
            f.write("\n".join(mot_predictions))
        print(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ d·ª± ƒëo√°n (MOT format) t·∫°i: {pred_path}")

        cap.release()
        out.release()
        cv2.destroyAllWindows()

        if frame_data:
            txt_path, report_content = save_test_report(
                frame_data, all_confs, self.output_folder, os.path.basename(self.video_path), 
                processed_count, total_frames, model_name, self.imgsz, self.stride, self.conf, tag
            )
            report_content += f"\n\n[TRACKING RESULT]\nT·ªïng s·ªë ƒë·ªëi t∆∞·ª£ng ƒë·ªôc nh·∫•t: {len(unique_ids)}"
            messagebox.showinfo("K·∫æT QU·∫¢ TEST", report_content)
        else:
            messagebox.showwarning("C·∫£nh b√°o", "Kh√¥ng c√≥ d·ªØ li·ªáu!")

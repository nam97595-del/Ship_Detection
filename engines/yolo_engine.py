import cv2
import time
import os
import numpy as np
from ultralytics import YOLO
from tkinter import messagebox
from utils.report_utils import save_test_report

class YoloTester:
    def __init__(self, model_path, video_path, output_folder, imgsz, stride, conf, iou, stop_event, tracker_type="bytetrack.yaml"):
        self.model_path = model_path
        self.video_path = video_path
        self.output_folder = output_folder
        self.imgsz = imgsz
        self.stride = stride
        self.conf = conf
        self.iou = iou
        self.stop_event = stop_event
        self.tracker_type = tracker_type

    def run(self):
        # --- Cáº¤U HÃŒNH GIAO DIá»†N ---
        DRAW_CFG = {
            "box_thick": 2,          # Äá»™ dÃ y khung hÃ¬nh chá»¯ nháº­t
            "font_scale": 0.6,       # Cá»¡ chá»¯
            "font_thick": 1,         # Äá»™ Ä‘áº­m cá»§a chá»¯
            "text_bg_alpha": 0.5,    # Äá»™ trong suá»‘t ná»n chá»¯ (0-1)
            "show_conf": True,       # Hiá»‡n Ä‘á»™ tin cáº­y
            
            # Mapping ID class sang tÃªn hiá»ƒn thá»‹ vÃ  mÃ u sáº¯c (BGR)
            "classes": {
                0: {"name": "F-Boat", "color": (0, 0, 255)},    # Äá» (Fishing)
                1: {"name": "P-Ship", "color": (255, 255, 0)},  # Xanh ngá»c (Passenger)
                2: {"name": "S-Boat", "color": (0, 255, 0)},    # Xanh lÃ¡ (Speed)
                # ThÃªm máº·c Ä‘á»‹nh náº¿u cÃ³ class láº¡
                "default": {"name": "Obj", "color": (255, 255, 255)} 
            }
        }
        # -----------------------------------------

        try:
            print(f"ðŸ”¹ Loading model: {self.model_path}")
            model = YOLO(self.model_path)
        except Exception as e:
            messagebox.showerror("Lá»—i", f"KhÃ´ng thá»ƒ load model:\n{e}")
            return

        cap = cv2.VideoCapture(self.video_path)
        if not cap.isOpened():
            messagebox.showerror("Lá»—i", f"KhÃ´ng má»Ÿ Ä‘Æ°á»£c video:\n{self.video_path}")
            return

        # Setup Video Writer
        orig_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        orig_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        orig_fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        input_name = os.path.splitext(os.path.basename(self.video_path))[0]
        model_name = os.path.splitext(os.path.basename(self.model_path))[0]
        tracker_tag = self.tracker_type.replace('.yaml', '').upper()
        tag = f"sz{self.imgsz}_skip{self.stride}_{tracker_tag}_CUSTOM"
        
        out_vid_name = f"{model_name}_vs_{input_name}_{tag}.mp4"
        out_vid_path = os.path.join(self.output_folder, out_vid_name)
        out = cv2.VideoWriter(out_vid_path, cv2.VideoWriter_fourcc(*'mp4v'), orig_fps, (orig_w, orig_h))

        # Setup Window
        window_name = f"YOLO Custom Draw - {model_name}"
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 1280, 720)

        frame_idx = 0
        processed_count = 0
        frame_data = []
        all_confs = []
        unique_ids = set() 

        while cap.isOpened() and not self.stop_event.is_set():
            success, frame = cap.read()
            if not success: break
            
            frame_idx += 1
            if frame_idx % self.stride != 0: continue 

            processed_count += 1
            start_t = time.time()
            
            # Tracking
            results = model.track(frame, persist=True, verbose=False, conf=self.conf, iou=self.iou, imgsz=self.imgsz, tracker=self.tracker_type)
            
            end_t = time.time()
            fps_curr = 1.0 / (end_t - start_t) if (end_t - start_t) > 0 else 0
            
            # --- CUSTOM DRAWING LOGIC (Báº®T Äáº¦U Váº¼ TAY) ---
            annotated_frame = frame.copy() # Copy áº£nh gá»‘c Ä‘á»ƒ váº½
            overlay = frame.copy()         # Layer Ä‘á»ƒ váº½ Ä‘á»™ trong suá»‘t (transparency)
            
            boxes = results[0].boxes
            
            if len(boxes) > 0:
                # Láº¥y dá»¯ liá»‡u dáº¡ng array Ä‘á»ƒ xá»­ lÃ½ nhanh hÆ¡n
                xyxys = boxes.xyxy.cpu().numpy().astype(int)
                ids = boxes.id.cpu().numpy().astype(int) if boxes.id is not None else [-1]*len(boxes)
                clss = boxes.cls.cpu().numpy().astype(int)
                confs = boxes.conf.cpu().numpy()
                
                # LÆ°u ID Ä‘á»ƒ thá»‘ng kÃª
                for t_id in ids:
                    if t_id != -1: unique_ids.add(t_id)
                    
                # VÃ²ng láº·p váº½ tá»«ng box
                for box, track_id, cls_id, conf in zip(xyxys, ids, clss, confs):
                    x1, y1, x2, y2 = box
                    
                    # 1. Láº¥y thÃ´ng tin class tá»« Config
                    class_info = DRAW_CFG["classes"].get(cls_id, DRAW_CFG["classes"]["default"])
                    color = class_info["color"]
                    label_name = class_info["name"]
                    
                    # 2. Váº½ Box (Khung hÃ¬nh chá»¯ nháº­t)
                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, DRAW_CFG["box_thick"])
                    
                    # 3. Táº¡o Label text (VÃ­ dá»¥: #5 F-Boat 0.85)
                    id_text = f"#{track_id}" if track_id != -1 else ""
                    conf_text = f"{conf:.2f}" if DRAW_CFG["show_conf"] else ""
                    label = f"{id_text} {label_name} {conf_text}".strip()
                    
                    # 4. TÃ­nh toÃ¡n kÃ­ch thÆ°á»›c ná»n chá»¯
                    (w_text, h_text), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, DRAW_CFG["font_scale"], DRAW_CFG["font_thick"])
                    
                    # Äáº·t vá»‹ trÃ­ chá»¯ (máº·c Ä‘á»‹nh á»Ÿ trÃªn Ä‘áº§u box, náº¿u trÃ n mÃ n hÃ¬nh thÃ¬ Ä‘Æ°a vÃ o trong)
                    text_y = y1 - 5 if y1 - h_text - 5 > 0 else y1 + h_text + 5
                    
                    # 5. Váº½ ná»n chá»¯ TRONG SUá»T (Kháº¯c phá»¥c viá»‡c che khuáº¥t)
                    # Váº½ hÃ¬nh chá»¯ nháº­t Ä‘áº·c lÃªn lá»›p overlay
                    cv2.rectangle(overlay, 
                                  (x1, text_y - h_text - 5), 
                                  (x1 + w_text, text_y + baseline), 
                                  color, -1) # -1 lÃ  tÃ´ kÃ­n mÃ u
                    
                    # Váº½ chá»¯ Ä‘Ã¨ lÃªn frame chÃ­nh
                    cv2.putText(annotated_frame, label, (x1, text_y), 
                                cv2.FONT_HERSHEY_SIMPLEX, DRAW_CFG["font_scale"], (255, 255, 255), DRAW_CFG["font_thick"], cv2.LINE_AA)

            # --- Gá»˜P LAYER TRONG SUá»T ---
            # CÃ´ng thá»©c: áº£nh_cuá»‘i = áº£nh_gá»‘c * alpha + lá»›p_mÃ u * (1-alpha)
            alpha = 1 - DRAW_CFG["text_bg_alpha"]
            annotated_frame = cv2.addWeighted(overlay, 1 - alpha, annotated_frame, alpha, 0)

            # --- Váº¼ THá»NG KÃŠ (UI) ---
            # Váº½ báº£ng thá»‘ng kÃª gá»n gÃ ng gÃ³c trÃ¡i
            cv2.rectangle(annotated_frame, (5, 5), (250, 85), (0, 0, 0), -1) # Ná»n Ä‘en cho UI
            cv2.putText(annotated_frame, f"FPS: {fps_curr:.1f}", (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)
            cv2.putText(annotated_frame, f"Objs Current: {len(boxes)}", (15, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 1)
            cv2.putText(annotated_frame, f"Total Count: {len(unique_ids)}", (15, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 1)
            
            out.write(annotated_frame)
            cv2.imshow(window_name, annotated_frame)

            # Collect Data
            if len(boxes) > 0: all_confs.extend(confs)
            if processed_count > 1:
                frame_data.append({
                    "Frame": frame_idx, "FPS": round(fps_curr, 2),
                    "Time_ms": round((end_t - start_t)*1000, 2),
                    "Objects_In_Frame": len(boxes),
                    "Total_Unique_Objects": len(unique_ids)
                })

            if cv2.waitKey(1) & 0xFF == ord('q'): break

        cap.release()
        out.release()
        cv2.destroyAllWindows()

        if frame_data:
            txt_path, report_content = save_test_report(
                frame_data, all_confs, self.output_folder, os.path.basename(self.video_path), 
                processed_count, total_frames, model_name, self.imgsz, self.stride, self.conf, tag
            )
            report_content += f"\n\n[TRACKING RESULT]\nTá»•ng sá»‘ Ä‘á»‘i tÆ°á»£ng Ä‘á»™c nháº¥t: {len(unique_ids)}"
            messagebox.showinfo("Káº¾T QUáº¢ TEST", report_content)
        else:
            messagebox.showwarning("Cáº£nh bÃ¡o", "KhÃ´ng cÃ³ dá»¯ liá»‡u!")
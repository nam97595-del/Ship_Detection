import cv2
import os
import time
import datetime
import numpy as np
import pandas as pd
import tkinter as tk
from tkinter import filedialog
from ultralytics import YOLO

# ==============================================================================
# C·∫§U H√åNH NG∆Ø·ªúI D√ôNG (CH·ªàNH S·ª¨A T·∫†I ƒê√ÇY)
# ==============================================================================
TEST_IMGSZ = 1280      # K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o (Convert size) -> Th∆∞·ªùng l√† 640
FRAME_STRIDE = 3      # Drop frame: X·ª≠ l√Ω 1 frame, b·ªè qua (FRAME_STRIDE - 1) frame. 
                      # = 1: X·ª≠ l√Ω t·∫•t c·∫£ (Kh√¥ng drop)
                      # = 3: Video 30fps s·∫Ω ch·ªâ x·ª≠ l√Ω nh∆∞ 10fps (Gi√∫p test nhanh h∆°n)
# ==============================================================================

def select_file():
    root = tk.Tk()
    root.withdraw()
    file_path = filedialog.askopenfilename(title="Ch·ªçn Video ƒë·ªÉ Test", filetypes=[("Video files", "*.mp4;*.avi;*.mkv")])
    return file_path

def select_folder():
    root = tk.Tk()
    root.withdraw()
    folder_path = filedialog.askdirectory(title="Ch·ªçn Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£")
    return folder_path

def run_yolo_test_v3(model_path):
    # 1. Setup ƒë∆∞·ªùng d·∫´n
    video_path = select_file()
    if not video_path:
        print("ƒê√£ h·ªßy ch·ªçn video.")
        return

    output_folder = select_folder()
    if not output_folder:
        print("ƒê√£ h·ªßy ch·ªçn th∆∞ m·ª•c l∆∞u.")
        return

    # 2. Load Model
    print(f"üîπ ƒêang load m√¥ h√¨nh: {os.path.basename(model_path)}...")
    try:
        model = YOLO(model_path)
    except Exception as e:
        print(f"‚ùå L·ªói load model: {e}")
        return

    # 3. Chu·∫©n b·ªã file output
    model_name = os.path.splitext(os.path.basename(model_path))[0]
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # T√™n file output ghi r√µ th√¥ng s·ªë ƒë·ªÉ d·ªÖ so s√°nh
    tag = f"sz{TEST_IMGSZ}_skip{FRAME_STRIDE}"
    output_video_name = f"{timestamp}_{model_name}_{tag}_video.mp4"
    raw_csv_name = f"{timestamp}_{model_name}_{tag}_raw.csv"
    report_name = f"{timestamp}_{model_name}_{tag}_REPORT.txt"
    
    output_video_path = os.path.join(output_folder, output_video_name)
    raw_csv_path = os.path.join(output_folder, raw_csv_name)
    report_path = os.path.join(output_folder, report_name)

    # 4. Config Video Capture
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"‚ùå Kh√¥ng th·ªÉ m·ªü video: {video_path}")
        return

    orig_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    orig_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    orig_fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames_input = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # T√≠nh to√°n FPS cho video ƒë·∫ßu ra (V√¨ drop frame n√™n video output s·∫Ω ng·∫Øn l·∫°i ho·∫∑c tua nhanh)
    # ·ªû ƒë√¢y ta gi·ªØ nguy√™n FPS g·ªëc ƒë·ªÉ video output tr√¥ng s·∫Ω b·ªã "tua nhanh" (timelapse)
    # nh∆∞ng ph·∫£n √°nh ƒë√∫ng c√°c frame ƒë√£ ƒë∆∞·ª£c detect.
    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), orig_fps, (orig_width, orig_height))

    # 5. C√†i ƒë·∫∑t hi·ªÉn th·ªã
    window_name = f"Test Result (Skip {FRAME_STRIDE}) - {model_name}"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL) 
    cv2.resizeWindow(window_name, 1280, 720)

    frame_data = []
    all_confidences = []
    processed_count = 0

    print(f"\nüöÄ B·∫Øt ƒë·∫ßu test: Imgsz={TEST_IMGSZ} | Drop Frame={FRAME_STRIDE} (X·ª≠ l√Ω 1/{FRAME_STRIDE} frames)")
    print("Nh·∫•n 'q' ƒë·ªÉ d·ª´ng s·ªõm.")

    frame_idx = 0
    
    while cap.isOpened():
        success, frame = cap.read()
        if not success:
            break
        
        frame_idx += 1

        # --- LOGIC DROP FRAME ---
        # N·∫øu frame hi·ªán t·∫°i kh√¥ng chia h·∫øt cho b∆∞·ªõc nh·∫£y th√¨ b·ªè qua
        if frame_idx % FRAME_STRIDE != 0:
            continue

        # B·∫Øt ƒë·∫ßu t√≠nh gi·ªù cho frame ƒë∆∞·ª£c ch·ªçn
        processed_count += 1
        start_time = time.time()

        # --- INFERENCE (Convert size t·∫°i ƒë√¢y) ---
        # imgsz=TEST_IMGSZ: Resize ·∫£nh v·ªÅ 640x640 (ho·∫∑c size kh√°c) tr∆∞·ªõc khi detect
        results = model(frame, verbose=False, conf=0.7, iou=0.5, imgsz=TEST_IMGSZ)
        
        end_time = time.time()
        process_time_ms = (end_time - start_time) * 1000
        # FPS t·ª©c th·ªùi (Instant FPS)
        current_fps = 1.0 / (end_time - start_time) if (end_time - start_time) > 0 else 0

        # --- X·ª¨ L√ù K·∫æT QU·∫¢ ---
        boxes = results[0].boxes
        num_objects = len(boxes)
        
        confs = boxes.conf.cpu().numpy() if len(boxes) > 0 else []
        if len(confs) > 0:
            avg_conf_frame = float(np.mean(confs))
            all_confidences.extend(confs)
        else:
            avg_conf_frame = 0.0

        # V·∫Ω v√† hi·ªÉn th·ªã
        annotated_frame = results[0].plot()

        # Hi·ªÉn th·ªã th√¥ng tin l√™n h√¨nh
        cv2.rectangle(annotated_frame, (0, 0), (450, 140), (0, 0, 0), -1)
        cv2.putText(annotated_frame, f"Model: {model_name}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(annotated_frame, f"Input Size: {TEST_IMGSZ}x{TEST_IMGSZ}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        cv2.putText(annotated_frame, f"Process FPS: {current_fps:.1f}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(annotated_frame, f"Skipping: {FRAME_STRIDE}x (Frame {frame_idx})", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)

        out.write(annotated_frame)
        cv2.imshow(window_name, annotated_frame)

        # L∆∞u d·ªØ li·ªáu
        if processed_count > 1: # B·ªè qua frame ƒë·∫ßu cho ·ªïn ƒë·ªãnh
            frame_data.append({
                "Original_Frame_Index": frame_idx,
                "FPS_Instant": round(current_fps, 2),
                "Inference_Time_ms": round(process_time_ms, 2),
                "Objects_Detected": num_objects,
                "Avg_Confidence": round(avg_conf_frame, 4)
            })

        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("ƒê√£ d·ª´ng b·ªüi ng∆∞·ªùi d√πng.")
            break

    # 6. D·ªçn d·∫πp
    cap.release()
    out.release()
    cv2.destroyAllWindows()

    # 7. B√ÅO C√ÅO
    if frame_data:
        df = pd.DataFrame(frame_data)
        
        avg_fps = df["FPS_Instant"].mean()
        avg_time = df["Inference_Time_ms"].mean()
        total_objects = df["Objects_Detected"].sum()
        overall_conf = np.mean(all_confidences) if len(all_confidences) > 0 else 0.0
        
        df.to_csv(raw_csv_path, index=False)

        report_content = f"""
==========================================================
B√ÅO C√ÅO TEST: {model_name}
==========================================================
1. C·∫§U H√åNH TEST
   - Video Input: {os.path.basename(video_path)}
   - Image Size (Resize): {TEST_IMGSZ}x{TEST_IMGSZ}
   - Frame Stride (Drop Frame): {FRAME_STRIDE} (X·ª≠ l√Ω 1 frame m·ªói {FRAME_STRIDE} frame)
   - T·ªïng s·ªë frame g·ªëc: {total_frames_input}
   - S·ªë frame th·ª±c t·∫ø ƒë√£ x·ª≠ l√Ω: {processed_count}

2. K·∫æT QU·∫¢ HI·ªÜU NƒÇNG
   - T·ªëc ƒë·ªô x·ª≠ l√Ω trung b√¨nh (FPS Process): {avg_fps:.2f}
   - Th·ªùi gian detect trung b√¨nh: {avg_time:.2f} ms/frame
   - T·ªïng object ph√°t hi·ªán: {total_objects}
   - ƒê·ªô tin c·∫≠y trung b√¨nh (Confidence): {overall_conf:.4f}

3. NOTE
   - Video output s·∫Ω tua nhanh g·∫•p {FRAME_STRIDE} l·∫ßn so v·ªõi th·ª±c t·∫ø v√¨ ƒë√£ b·ªè b·ªõt frame.
==========================================================
        """

        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report_content)

        print(report_content)
        print(f"\n‚úÖ ƒê√£ xong. File l∆∞u t·∫°i: {output_folder}")
    else:
        print("Kh√¥ng c√≥ d·ªØ li·ªáu.")

if __name__ == "__main__":
    root = tk.Tk()
    root.withdraw()
    print("Ch·ªçn Model YOLO (.pt)...")
    selected_model = filedialog.askopenfilename( title="Ch·ªçn Model YOLO (.pt / .engine)", filetypes=[("All Model Files", "*.pt;*.engine;*.onnx")])
    
    if selected_model:
        run_yolo_test_v3(selected_model)
    else:
        print("Ch∆∞a ch·ªçn model!")
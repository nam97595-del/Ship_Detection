import cv2
import os
import time
import datetime
import numpy as np
import pandas as pd
import torch
import tkinter as tk
from tkinter import filedialog
from ultralytics import RTDETR
import supervision as sv

# --- C·∫§U H√åNH GIAO DI·ªÜN V·∫º (ƒê√É CH·ªàNH S·ª¨A CHO D·ªÑ NH√åN) ---
BOX_THICKNESS = 3           # ƒê·ªô d√†y khung bao v·∫≠t th·ªÉ
TEXT_SCALE = 1.0            # C·ª° ch·ªØ (TƒÉng t·ª´ 0.7 -> 1.0)
TEXT_THICKNESS = 2          # ƒê·ªô ƒë·∫≠m ch·ªØ (TƒÉng l√™n 2 cho r√µ)
TEXT_PADDING = 15           # Kho·∫£ng c√°ch ƒë·ªám ch·ªØ (TƒÉng l√™n ƒë·ªÉ n·ªÅn ch·ªØ r·ªông h∆°n)
CONFIDENCE_THRESHOLD = 0.75  # Ng∆∞·ª°ng l·ªçc

# M√†u s·∫Øc cho b·∫£ng th√¥ng s·ªë (BGR)
COLOR_BG_INFO = (30, 30, 30)    # M√†u n·ªÅn b·∫£ng th√¥ng tin (X√°m ƒë·∫≠m)
COLOR_TEXT_LABEL = (200, 200, 200) # M√†u t√™n th√¥ng s·ªë (X√°m nh·∫°t)
COLOR_TEXT_VALUE = (0, 255, 255)   # M√†u gi√° tr·ªã (V√†ng s√°ng)

def select_file():
    root = tk.Tk(); root.withdraw()
    return filedialog.askopenfilename(title="Ch·ªçn Model (.pt, .onnx, .engine)", 
                                    filetypes=[("Models", "*.pt;*.onnx;*.engine")])

def select_video():
    root = tk.Tk(); root.withdraw()
    return filedialog.askopenfilename(title="Ch·ªçn Video Input", filetypes=[("Video", "*.mp4;*.avi;*.mkv")])

def select_folder():
    root = tk.Tk(); root.withdraw()
    return filedialog.askdirectory(title="Ch·ªçn Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£")

def draw_info_panel(frame, model_name, fps, num_objects, conf):
    """H√†m v·∫Ω b·∫£ng th√¥ng s·ªë chuy√™n nghi·ªáp, d·ªÖ ƒë·ªçc h∆°n"""
    # T·∫°o overlay n·ªÅn t·ªëi
    h, w, _ = frame.shape
    panel_w = 400
    panel_h = 140
    
    # V·∫Ω h√¨nh ch·ªØ nh·∫≠t bo g√≥c (ho·∫∑c ch·ªØ nh·∫≠t th∆∞·ªùng) l√†m n·ªÅn
    sub_img = frame[0:panel_h, 0:panel_w]
    black_rect = np.full(sub_img.shape, COLOR_BG_INFO, dtype=np.uint8)
    
    # Blend m√†u n·ªÅn v·ªõi video (ƒë·ªô trong su·ªët 0.7) ƒë·ªÉ nh√¨n hi·ªán ƒë·∫°i h∆°n
    res = cv2.addWeighted(sub_img, 0.3, black_rect, 0.7, 1.0)
    frame[0:panel_h, 0:panel_w] = res
    
    # C·∫•u h√¨nh font ch·ªØ ƒë·∫πp h∆°n (HERSHEY_COMPLEX)
    font = cv2.FONT_HERSHEY_COMPLEX
    font_scale = 0.7
    thickness = 1
    line_h = 35 # Kho·∫£ng c√°ch c√°c d√≤ng
    x_start = 15
    y_start = 35

    # D√≤ng 1: Model Name
    cv2.putText(frame, "Model:", (x_start, y_start), font, font_scale, COLOR_TEXT_LABEL, thickness, cv2.LINE_AA)
    cv2.putText(frame, model_name[:20], (x_start + 80, y_start), font, font_scale, (255, 255, 255), 2, cv2.LINE_AA)

    # D√≤ng 2: FPS
    cv2.putText(frame, "FPS:", (x_start, y_start + line_h), font, font_scale, COLOR_TEXT_LABEL, thickness, cv2.LINE_AA)
    # T√¥ m√†u FPS: Xanh n·∫øu > 20, ƒê·ªè n·∫øu th·∫•p
    fps_color = (0, 255, 0) if fps > 20 else (0, 0, 255)
    cv2.putText(frame, f"{fps:.1f}", (x_start + 80, y_start + line_h), font, font_scale+0.1, fps_color, 2, cv2.LINE_AA)

    # D√≤ng 3: Objects
    cv2.putText(frame, "Count:", (x_start, y_start + line_h*2), font, font_scale, COLOR_TEXT_LABEL, thickness, cv2.LINE_AA)
    cv2.putText(frame, f"{num_objects}", (x_start + 80, y_start + line_h*2), font, font_scale, COLOR_TEXT_VALUE, 2, cv2.LINE_AA)

    # D√≤ng 4: Avg Conf
    cv2.putText(frame, "Conf:", (x_start + 160, y_start + line_h*2), font, font_scale, COLOR_TEXT_LABEL, thickness, cv2.LINE_AA)
    cv2.putText(frame, f"{conf:.0%}", (x_start + 230, y_start + line_h*2), font, font_scale, COLOR_TEXT_VALUE, 2, cv2.LINE_AA)

    return frame

def run_full_report_test(model_path):
    # 1. SETUP
    print(f"üîπ ƒêang load model: {os.path.basename(model_path)}")
    try:
        model = RTDETR(model_path)
    except Exception as e:
        print(f"‚ùå L·ªói load model: {e}")
        return

    device = 0 if torch.cuda.is_available() else 'cpu'
    print(f"üñ•Ô∏è  Ph·∫ßn c·ª©ng: {'GPU (CUDA)' if device==0 else 'CPU'}")

    video_path = select_video()
    if not video_path: return
    output_folder = select_folder()
    if not output_folder: return

    # T√™n file
    model_name = os.path.splitext(os.path.basename(model_path))[0]
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    out_video_name = f"{timestamp}_{model_name}_Result.mp4"
    out_csv_name = f"{timestamp}_{model_name}_Metrics.csv"
    out_report_name = f"{timestamp}_{model_name}_FULL_REPORT.txt"

    out_path = os.path.join(output_folder, out_video_name)
    csv_path = os.path.join(output_folder, out_csv_name)
    report_path = os.path.join(output_folder, out_report_name)

    # Video Capture
    cap = cv2.VideoCapture(video_path)
    fps_in = cap.get(cv2.CAP_PROP_FPS)
    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames_input = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps_in, (w, h))

    # 2. SETUP SUPERVISION (C·∫§U H√åNH L·∫†I CHO ƒê·∫∏P)
    box_annotator = sv.BoxAnnotator(
        thickness=BOX_THICKNESS,
        color=sv.ColorPalette.DEFAULT 
    )
    # LabelAnnotator m·ªõi gi√∫p ch·ªØ n·∫±m trong box m√†u n·ªÅn, d·ªÖ ƒë·ªçc h∆°n
    label_annotator = sv.LabelAnnotator(
        text_scale=TEXT_SCALE,          # Ch·ªØ to h∆°n
        text_thickness=TEXT_THICKNESS,  # Ch·ªØ ƒë·∫≠m h∆°n
        text_padding=TEXT_PADDING,      # Padding r·ªông h∆°n
        text_position=sv.Position.TOP_CENTER,
        color=sv.ColorPalette.DEFAULT
    )

    # C·ª≠a s·ªï hi·ªÉn th·ªã
    window_name = f"Test Result - {model_name}"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(window_name, 1280, 720)

    # --- BI·∫æN L∆ØU TR·ªÆ D·ªÆ LI·ªÜU B√ÅO C√ÅO ---
    frame_data = []        
    all_confidences = []   

    print(f"\nüöÄ B·∫Øt ƒë·∫ßu test video ({total_frames_input} frames)... Nh·∫•n 'q' ƒë·ªÉ d·ª´ng.")
    
    frame_idx = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        
        start_time = time.time()
        frame_idx += 1

        # --- INFERENCE ---
        results = model(frame, verbose=False, conf=CONFIDENCE_THRESHOLD, iou=0.45)
        
        speed_dict = results[0].speed
        inference_time_ms = speed_dict['inference'] + speed_dict['postprocess'] 
        
        end_time = time.time()
        real_proc_time = end_time - start_time
        fps = 1.0 / real_proc_time if real_proc_time > 0 else 0

        # --- X·ª¨ L√ù DATA ---
        detections = sv.Detections.from_ultralytics(results[0])
        num_objects = len(detections)

        if num_objects > 0:
            current_confs = detections.confidence.tolist()
            all_confidences.extend(current_confs)
            avg_conf_frame = np.mean(current_confs)
        else:
            avg_conf_frame = 0.0

        # --- V·∫º H√åNH (ƒê√É C·∫¢I TI·∫æN) ---
        # Format label: "Person 90%" thay v√¨ "Person 0.90" -> D·ªÖ ƒë·ªçc h∆°n
        labels = [
            f"{model.names[class_id]} {confidence:.0%}" 
            for class_id, confidence
            in zip(detections.class_id, detections.confidence)
        ]

        annotated_frame = frame.copy()
        annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)
        annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)

        # --- V·∫º INFO PANEL M·ªöI ---
        annotated_frame = draw_info_panel(annotated_frame, model_name, fps, num_objects, avg_conf_frame)

        out.write(annotated_frame)
        cv2.imshow(window_name, annotated_frame)

        # L∆∞u metrics
        if frame_idx > 5:
            frame_data.append({
                "Frame": frame_idx,
                "FPS": round(fps, 2),
                "Inference_Time_ms": round(inference_time_ms, 2),
                "Objects_Detected": num_objects,
                "Avg_Confidence": round(avg_conf_frame, 4)
            })

        if cv2.waitKey(1) == ord('q'): break

    cap.release()
    out.release()
    cv2.destroyAllWindows()

    # --- 3. T·∫†O B√ÅO C√ÅO CHI TI·∫æT ---
    if frame_data:
        df = pd.DataFrame(frame_data)
        
        avg_fps = df["FPS"].mean()
        min_fps = df["FPS"].min()
        max_fps = df["FPS"].max()
        avg_latency = df["Inference_Time_ms"].mean()
        
        total_objects_detected = df["Objects_Detected"].sum()
        avg_objects_per_frame = df["Objects_Detected"].mean()
        
        no_detect_frames = len(df[df["Objects_Detected"] == 0])
        detect_frames = len(df) - no_detect_frames
        
        if len(all_confidences) > 0:
            overall_avg_conf = np.mean(all_confidences)
        else:
            overall_avg_conf = 0.0

        df.to_csv(csv_path, index=False)

        report_content = f"""
==========================================================
B√ÅO C√ÅO HI·ªÜU NƒÇNG MODEL: {model_name.upper()}
Th·ªùi gian test: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
Video input: {os.path.basename(video_path)}
==========================================================

1. HI·ªÜU SU·∫§T T·ªêC ƒê·ªò (SPEED)
   - FPS Trung b√¨nh (Avg FPS): {avg_fps:.2f}
   - FPS Th·∫•p nh·∫•t (Min FPS):  {min_fps:.2f}
   - FPS Cao nh·∫•t (Max FPS):   {max_fps:.2f}
   - ƒê·ªô tr·ªÖ trung b√¨nh (Latency): {avg_latency:.2f} ms

2. KH·∫¢ NƒÇNG PH√ÅT HI·ªÜN (DETECTION ACCURACY)
   - T·ªïng s·ªë frame ƒë√£ test: {len(df)}
   - ƒê·ªô tin c·∫≠y trung b√¨nh: {overall_avg_conf:.2%} ({overall_avg_conf:.4f})
   
   - T·ªïng s·ªë v·∫≠t th·ªÉ ph√°t hi·ªán: {total_objects_detected}
   - Trung b√¨nh s·ªë v·∫≠t th·ªÉ/frame: {avg_objects_per_frame:.2f}
   
   - S·ªë frame c√≥ ph√°t hi·ªán: {detect_frames} ({detect_frames/len(df)*100:.1f}%)
   - S·ªë frame KH√îNG ph√°t hi·ªán: {no_detect_frames} ({no_detect_frames/len(df)*100:.1f}%)

3. FILE K·∫æT QU·∫¢
   - Video Output: {os.path.basename(out_path)}
   - Data chi ti·∫øt (CSV): {os.path.basename(csv_path)}
==========================================================
        """

        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report_content)

        print("\n" + "="*40)
        print("‚úÖ HO√ÄN TH√ÄNH TEST!")
        print(f"üìÑ B√°o c√°o ƒë·∫ßy ƒë·ªß ƒë√£ l∆∞u t·∫°i: {report_path}")
        print("="*40)
        print(report_content)
        
    else:
        print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ t·∫°o b√°o c√°o.")

if __name__ == "__main__":
    print("Ch·ªçn model RT-DETR...")
    path = select_file()
    if path:
        run_full_report_test(path)
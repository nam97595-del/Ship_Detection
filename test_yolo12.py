import cv2
import os
import time
import datetime
import numpy as np
import pandas as pd
import tkinter as tk
from tkinter import filedialog
from ultralytics import YOLO

def select_file():
    root = tk.Tk()
    root.withdraw()
    file_path = filedialog.askopenfilename(title="Ch·ªçn Video ƒë·ªÉ Test", filetypes=[("Video files", "*.mp4;*.avi;*.mkv")])
    return file_path

def select_folder():
    root = tk.Tk()
    root.withdraw()
    folder_path = filedialog.askdirectory(title="Ch·ªçn Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£")
    return folder_path

def run_yolo_test_v2(model_path):
    # 1. Setup ƒë∆∞·ªùng d·∫´n
    video_path = select_file()
    if not video_path:
        print("ƒê√£ h·ªßy ch·ªçn video.")
        return

    output_folder = select_folder()
    if not output_folder:
        print("ƒê√£ h·ªßy ch·ªçn th∆∞ m·ª•c l∆∞u.")
        return

    # 2. Load Model
    print(f"üîπ ƒêang load m√¥ h√¨nh: {os.path.basename(model_path)}...")
    try:
        model = YOLO(model_path)
    except Exception as e:
        print(f"‚ùå L·ªói load model: {e}")
        return

    # 3. Chu·∫©n b·ªã file output
    model_name = os.path.splitext(os.path.basename(model_path))[0]
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # T√™n c√°c file k·∫øt qu·∫£
    output_video_name = f"{timestamp}_{model_name}_video.mp4"
    raw_csv_name = f"{timestamp}_{model_name}_raw_metrics.csv"
    report_name = f"{timestamp}_{model_name}_SUMMARY_REPORT.txt"
    
    output_video_path = os.path.join(output_folder, output_video_name)
    raw_csv_path = os.path.join(output_folder, raw_csv_name)
    report_path = os.path.join(output_folder, report_name)

    # 4. Config Video Capture
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"‚ùå Kh√¥ng th·ªÉ m·ªü video: {video_path}")
        return

    orig_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    orig_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps_input = cap.get(cv2.CAP_PROP_FPS)
    total_frames_input = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # Video Writer
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video_path, fourcc, fps_input, (orig_width, orig_height))

    # 5. C√†i ƒë·∫∑t hi·ªÉn th·ªã (Tr√°nh tr√†n m√†n h√¨nh)
    window_name = f"Test Result - {model_name}"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL) 
    cv2.resizeWindow(window_name, 1280, 720) # Resize v·ªõi c·ª≠a s·ªë th√≠ch h·ª£p

    # List l∆∞u d·ªØ li·ªáu th√¥
    frame_data = []
    
    # List l∆∞u confidences to√†n b·ªô video ƒë·ªÉ t√≠nh trung b√¨nh
    all_confidences = []

    print(f"\nüöÄ B·∫Øt ƒë·∫ßu test video ({total_frames_input} frames)... Nh·∫•n 'q' ƒë·ªÉ d·ª´ng s·ªõm.")

    frame_idx = 0
    
    while cap.isOpened():
        start_time = time.time()
        success, frame = cap.read()
        
        if not success:
            break
        
        frame_idx += 1

        # --- INFERENCE ---
        # conf=0.25: Ch·ªâ l·∫•y box c√≥ ƒë·ªô tin c·∫≠y > 25%
        results = model(frame, verbose=False, conf=0.7, iou=0.5)
        
        # L·∫•y th√¥ng s·ªë th·ªùi gian th·ª±c t·∫ø ƒëo ƒë∆∞·ª£c (bao g·ªìm preprocess + inference + postprocess)
        end_time = time.time()
        process_time_ms = (end_time - start_time) * 1000
        current_fps = 1.0 / (end_time - start_time) if (end_time - start_time) > 0 else 0

        # --- X·ª¨ L√ù K·∫æT QU·∫¢ DETECT ---
        boxes = results[0].boxes
        num_objects = len(boxes)
        
        # L·∫•y danh s√°ch ƒë·ªô tin c·∫≠y (confidence scores) trong frame n√†y
        # Chuy·ªÉn sang CPU v√† numpy ƒë·ªÉ t√≠nh to√°n
        confs = boxes.conf.cpu().numpy() if len(boxes) > 0 else []
        if len(confs) > 0:
            avg_conf_frame = float(np.mean(confs))
            all_confidences.extend(confs) # Gom v√†o list t·ªïng
        else:
            avg_conf_frame = 0.0

        # V·∫Ω h√¨nh
        annotated_frame = results[0].plot()

        # Hi·ªÉn th·ªã th√¥ng s·ªë l√™n video
        # V·∫Ω n·ªÅn ƒëen m·ªù ƒë·ªÉ ch·ªØ d·ªÖ ƒë·ªçc h∆°n
        cv2.rectangle(annotated_frame, (0, 0), (400, 120), (0, 0, 0), -1)
        cv2.putText(annotated_frame, f"Model: {model_name}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(annotated_frame, f"FPS: {current_fps:.1f}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(annotated_frame, f"Objects: {num_objects}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        cv2.putText(annotated_frame, f"Avg Conf: {avg_conf_frame:.2f}", (200, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 165, 255), 2)

        out.write(annotated_frame)
        cv2.imshow(window_name, annotated_frame)

        # L∆∞u d·ªØ li·ªáu th√¥ (B·ªè qua frame ƒë·∫ßu ti√™n v√¨ th∆∞·ªùng b·ªã lag kh·ªüi ƒë·ªông)
        if frame_idx > 1:
            frame_data.append({
                "Frame": frame_idx,
                "FPS": round(current_fps, 2),
                "Inference_Time_ms": round(process_time_ms, 2),
                "Objects_Detected": num_objects,
                "Avg_Confidence": round(avg_conf_frame, 4)
            })

        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("ƒê√£ d·ª´ng b·ªüi ng∆∞·ªùi d√πng.")
            break

    # 6. D·ªçn d·∫πp
    cap.release()
    out.release()
    cv2.destroyAllWindows()

    # 7. T√çNH TO√ÅN & XU·∫§T B√ÅO C√ÅO (AGGREGATION)
    if frame_data:
        df = pd.DataFrame(frame_data)
        
        # T√≠nh to√°n c√°c ch·ªâ s·ªë t·ªïng h·ª£p
        avg_fps = df["FPS"].mean()
        avg_time = df["Inference_Time_ms"].mean()
        min_fps = df["FPS"].min()
        max_fps = df["FPS"].max()
        
        total_objects_detected = df["Objects_Detected"].sum()
        avg_objects_per_frame = df["Objects_Detected"].mean()
        frames_with_no_detection = len(df[df["Objects_Detected"] == 0])
        
        # T√≠nh ƒë·ªô tin c·∫≠y trung b√¨nh c·ªßa TO√ÄN B·ªò c√°c box ƒë√£ detect
        overall_avg_conf = np.mean(all_confidences) if len(all_confidences) > 0 else 0.0

        # L∆∞u file CSV chi ti·∫øt
        df.to_csv(raw_csv_path, index=False)

        # T·∫°o n·ªôi dung b√°o c√°o
        report_content = f"""
==========================================================
B√ÅO C√ÅO HI·ªÜU NƒÇNG MODEL: {model_name}
Ng√†y test: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
Video input: {os.path.basename(video_path)}
==========================================================

1. HI·ªÜU SU·∫§T T·ªêC ƒê·ªò (SPEED)
   - FPS Trung b√¨nh (Avg FPS): {avg_fps:.2f}
   - FPS Th·∫•p nh·∫•t (Min FPS):  {min_fps:.2f} (Drop frame)
   - FPS Cao nh·∫•t (Max FPS):   {max_fps:.2f}
   - Th·ªùi gian x·ª≠ l√Ω trung b√¨nh m·ªói frame: {avg_time:.2f} ms

2. KH·∫¢ NƒÇNG PH√ÅT HI·ªÜN (DETECTION CAPABILITY)
   - T·ªïng s·ªë frame ƒë√£ test: {len(df)}
   - T·ªïng s·ªë t√†u/b√® ph√°t hi·ªán ƒë∆∞·ª£c: {total_objects_detected}
   - S·ªë l∆∞·ª£ng t√†u trung b√¨nh/frame: {avg_objects_per_frame:.2f}
   - ƒê·ªô tin c·∫≠y trung b√¨nh (Avg Confidence): {overall_avg_conf:.4f} (Max 1.0)
     -> Ch·ªâ s·ªë n√†y c√†ng cao nghƒ©a l√† model c√†ng "t·ª± tin" v·ªõi d·ª± ƒëo√°n c·ªßa m√¨nh.
   - S·ªë frame kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c g√¨: {frames_with_no_detection} ({frames_with_no_detection/len(df)*100:.1f}%)

3. FILE K·∫æT QU·∫¢
   - Video output: {os.path.basename(output_video_path)}
   - Data chi ti·∫øt: {os.path.basename(raw_csv_path)}
==========================================================
        """

        # Ghi file b√°o c√°o .txt
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report_content)

        print(report_content)
        print(f"\n‚úÖ ƒê√£ l∆∞u b√°o c√°o t·∫°i: {report_path}")

    else:
        print("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ b√°o c√°o (Video qu√° ng·∫Øn ho·∫∑c l·ªói).")

if __name__ == "__main__":
    print("Vui l√≤ng ch·ªçn file model .pt (YOLO)")
    root = tk.Tk()
    root.withdraw()
    selected_model = filedialog.askopenfilename(title="Ch·ªçn Model YOLO (.pt)", filetypes=[("Model files", "*.pt")])
    
    if selected_model:
        run_yolo_test_v2(selected_model)
    else:
        print("Ch∆∞a ch·ªçn model!")